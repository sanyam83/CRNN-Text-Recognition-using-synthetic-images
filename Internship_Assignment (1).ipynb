{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Internship Assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etk0INVcDiVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_drive_path = '/content/gdrive'\n",
        "from google.colab import drive\n",
        "drive.mount(g_drive_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfYUb5bx3nmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8bd7c396-033d-4832-d513-758d942b1c95"
      },
      "source": [
        "!git clone https://github.com/sanyam83/text_renderer.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'text_renderer'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 725 (delta 33), reused 0 (delta 0), pack-reused 653\u001b[K\n",
            "Receiving objects: 100% (725/725), 11.63 MiB | 27.12 MiB/s, done.\n",
            "Resolving deltas: 100% (345/345), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MAtpOL4Z3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c980319a-aa28-4306-a218-45cdd75fce66"
      },
      "source": [
        "%cd /content/text_renderer\n",
        "!python setup.py develop"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/text_renderer\n",
            "running develop\n",
            "running egg_info\n",
            "creating text_renderer.egg-info\n",
            "writing text_renderer.egg-info/PKG-INFO\n",
            "writing dependency_links to text_renderer.egg-info/dependency_links.txt\n",
            "writing top-level names to text_renderer.egg-info/top_level.txt\n",
            "writing manifest file 'text_renderer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'text_renderer.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/text-renderer.egg-link (link to .)\n",
            "Adding text-renderer 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/text_renderer\n",
            "Processing dependencies for text-renderer==0.0.1\n",
            "Finished processing dependencies for text-renderer==0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-Nm2Ah4j4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e14133f3-8607-42b9-87a6-28df68f63d0f"
      },
      "source": [
        "!pip install -r docker/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.5.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e1/d3eed618272f4b746339af1a84b2511e79c1708d88a9195cf25d743fa614/opencv_python-3.4.5.20-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 119kB/s \n",
            "\u001b[?25hCollecting fontTools==4.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/80/6703106d6e3a56d0b124a2a1b3159d70ef383282b428a385bbee39762030/fonttools-4.12.1-py3-none-any.whl (803kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 44.0MB/s \n",
            "\u001b[?25hCollecting lmdb==0.98\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/5c/d56dbc2532ecf14fa004c543927500c0f645eaca8bd7ec39420c7546396a/lmdb-0.98.tar.gz (869kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 36.1MB/s \n",
            "\u001b[?25hCollecting pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 34.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 5)) (1.18.5)\n",
            "Collecting tenacity\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/05/ff089032442058bd3386f9cd991cd88ccac81dca1494d78751621ee35e62/tenacity-6.2.0-py2.py3-none-any.whl\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 8)) (4.41.1)\n",
            "Collecting loguru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/4f/baee593c195cd4b56cf008c9473347f3b0795b47d3b946e03706a8b43fca/loguru-0.5.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 10)) (1.14.2)\n",
            "Collecting sphinx==3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/bb/bbe3f555751da411ed892526d0d78ed1b9ff2a25ed2b0dab9f2670c8da07/Sphinx-3.1.2-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.4MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/86/1addf25a238bbd8466bb099f23d9a9f13494b22b37b44f6c41a778b8730f/sphinx_rtd_theme-0.5.0-py2.py3-none-any.whl (10.8MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 13)) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 14)) (3.6.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tenacity->-r docker/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->-r docker/requirements.txt (line 7)) (1.1.0)\n",
            "Collecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->-r docker/requirements.txt (line 10)) (2.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (20.4)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.8.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.11.2)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.1.4)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: docutils>=0.12 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (0.15.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.2.0)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (49.6.0)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (20.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (8.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (1.9.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (0.7.1)\n",
            "Collecting contextvars==2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel>=1.3->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (3.0.4)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: lmdb, fire, contextvars\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-0.98-cp36-cp36m-linux_x86_64.whl size=218603 sha256=319701253c12571775d5278a3064c7388834dd5b2be540d01f70ae7a33fefef5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/97/8c/7721e4b6b0ac723c6cc45ecca60599a80f75e2367330647390\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=0c3d8cae9a148795b28765ead8721c94b1d68e374d161a4c5fcb0c661036d056\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=dd4c8a09d3a92db20a241c9551984aeded09b0ed1fef157314f8be59e6fafdaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built lmdb fire contextvars\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python, fontTools, lmdb, pillow, tenacity, fire, immutables, contextvars, aiocontextvars, loguru, sphinxcontrib-jsmath, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinx, sphinx-rtd-theme\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: Sphinx 1.8.5\n",
            "    Uninstalling Sphinx-1.8.5:\n",
            "      Successfully uninstalled Sphinx-1.8.5\n",
            "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 fire-0.3.1 fontTools-4.12.1 immutables-0.14 lmdb-0.98 loguru-0.5.1 opencv-python-3.4.5.20 pillow-6.2.2 sphinx-3.1.2 sphinx-rtd-theme-0.5.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 tenacity-6.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqWGJwo6God",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a2d904ec-378f-4d00-96c8-fecfed7e257b"
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] --config CONFIG [--dataset {lmdb,img}]\n",
            "               [--num_processes NUM_PROCESSES] [--log_period LOG_PERIOD]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --config CONFIG       python file path\n",
            "  --dataset {lmdb,img}\n",
            "  --num_processes NUM_PROCESSES\n",
            "  --log_period LOG_PERIOD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49C3qavAaHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d0f8b69-781c-4511-ecce-73f364cd6e77"
      },
      "source": [
        "!python main.py \\\n",
        "    --config example_data/example.py \\\n",
        "    --dataset img \\\n",
        "    --num_processes 1 \\\n",
        "    --log_period 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m2020-08-31 08:44:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/eng.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/eng.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.00%(0) chars in input text。Unique chars(0): set()\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.word_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mLoad 158 words\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.00%(0) chars in input text。Unique chars(0): set()\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:00.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:01.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/char_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-31 08:44:01.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 350\u001b[0m\n",
            "\u001b[32m2020-08-31 08:45:56.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-31 08:45:56.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m100.00%(10000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-31 08:45:56.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 10000. Total: 10000\u001b[0m\n",
            "\u001b[32m2020-08-31 08:45:57.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/rand_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-31 08:45:57.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 30626\u001b[0m\n",
            "\u001b[32m2020-08-31 08:47:09.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-31 08:47:09.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m200.00%(20000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-31 08:47:09.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 20000. Total: 20000\u001b[0m\n",
            "\u001b[32m2020-08-31 08:47:10.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/word_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-31 08:47:10.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 60803\u001b[0m\n",
            "\u001b[32m2020-08-31 08:48:48.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-31 08:48:48.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m300.00%(30000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-31 08:48:48.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 30000. Total: 30000\u001b[0m\n",
            "\u001b[32m2020-08-31 08:48:48.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/same_line_data: 0\u001b[0m\n",
            "\u001b[32m2020-08-31 08:48:49.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 91036\u001b[0m\n",
            "\u001b[32m2020-08-31 08:52:33.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-31 08:52:33.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m400.00%(40000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-31 08:52:33.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 40000. Total: 40000\u001b[0m\n",
            "\u001b[32m2020-08-31 08:52:33.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/extra_text_line_data: 0\u001b[0m\n",
            "\u001b[32m2020-08-31 08:52:34.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 121557\u001b[0m\n",
            "\u001b[32m2020-08-31 08:54:24.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-31 08:54:24.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m500.00%(50000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-31 08:54:24.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 50000. Total: 50000\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVrU4o8bOy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json \n",
        "import csv \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json ('/content/text_renderer/example_data/output/word_corpus/labels.json')  \n",
        "df.to_csv ('/content/text_renderer/data_sample.csv', index = None, header=True)  \n",
        "df_1 = pd.read_json('/content/text_renderer/example_data/output/char_corpus/labels.json')\n",
        "df_1.to_csv ('/content/text_renderer/data_sample_1.csv', index = None, header=True)  \n",
        "df_2 = pd.read_json ('/content/text_renderer/example_data/output/extra_text_line_data/labels.json')  \n",
        "df_2.to_csv ('/content/text_renderer/data_sample_2.csv', index = None, header=True)  \n",
        "df_3 = pd.read_json('/content/text_renderer/example_data/output/rand_corpus/labels.json')\n",
        "df_3.to_csv ('/content/text_renderer/data_sample_3.csv', index = None, header=True)  \n",
        "df_4 = pd.read_json('/content/text_renderer/example_data/output/same_line_data/labels.json')\n",
        "df_4.to_csv ('/content/text_renderer/data_sample_4.csv', index = None, header=True)  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmZy0GDzTFvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ed4ab601-596a-4652-bf1f-5e30d1cb6166"
      },
      "source": [
        "  df_3"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num-samples</th>\n",
              "      <th>labels</th>\n",
              "      <th>sizes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000010000.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>37527851</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000010001.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>668805142</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000010002.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>294424</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000010003.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>666635</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000010004.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>96973</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000019995.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>85516</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000019996.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>16325913</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000019997.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>750025754</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000019998.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>4633730</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/rand_corpus/images/000019999.jpg</th>\n",
              "      <td>20000</td>\n",
              "      <td>7285244</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    num-samples  ...  sizes\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "...                                                         ...  ...    ...\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "/content/text_renderer/example_data/output/rand...        20000  ...    NaN\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udje1O1XObch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([df_1, df_3, df, df_4, df_2], axis = 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqPSTpVLTuuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['num-samples'], axis = 1)\n",
        "df = df.drop(['sizes'], axis = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUGf8xIT7ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['image_name'] = df.index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScYRd94bPkIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "9e566ef1-c520-4759-8b81-0fb404e8dd46"
      },
      "source": [
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/char_corpus/images/000000000.jpg</th>\n",
              "      <td>FOR AL</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/char_corpus/images/000000001.jpg</th>\n",
              "      <td>FLYIN</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/char_corpus/images/000000002.jpg</th>\n",
              "      <td>EVERS W</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/char_corpus/images/000000003.jpg</th>\n",
              "      <td>ORN WHY</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/char_corpus/images/000000004.jpg</th>\n",
              "      <td>S BOUG</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/extra_text_line_data/images/000049995.jpg</th>\n",
              "      <td>S ON 30 P</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/extra_text_line_data/images/000049996.jpg</th>\n",
              "      <td>ES STREET</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/extra_text_line_data/images/000049997.jpg</th>\n",
              "      <td>PERB FIEL</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/extra_text_line_data/images/000049998.jpg</th>\n",
              "      <td>UMB TO TH</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>/content/text_renderer/example_data/output/extra_text_line_data/images/000049999.jpg</th>\n",
              "      <td>T RAINALD</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       labels                                         image_name\n",
              "/content/text_renderer/example_data/output/char...     FOR AL  /content/text_renderer/example_data/output/cha...\n",
              "/content/text_renderer/example_data/output/char...      FLYIN  /content/text_renderer/example_data/output/cha...\n",
              "/content/text_renderer/example_data/output/char...    EVERS W  /content/text_renderer/example_data/output/cha...\n",
              "/content/text_renderer/example_data/output/char...   ORN WHY   /content/text_renderer/example_data/output/cha...\n",
              "/content/text_renderer/example_data/output/char...     S BOUG  /content/text_renderer/example_data/output/cha...\n",
              "...                                                       ...                                                ...\n",
              "/content/text_renderer/example_data/output/extr...  S ON 30 P  /content/text_renderer/example_data/output/ext...\n",
              "/content/text_renderer/example_data/output/extr...  ES STREET  /content/text_renderer/example_data/output/ext...\n",
              "/content/text_renderer/example_data/output/extr...  PERB FIEL  /content/text_renderer/example_data/output/ext...\n",
              "/content/text_renderer/example_data/output/extr...  UMB TO TH  /content/text_renderer/example_data/output/ext...\n",
              "/content/text_renderer/example_data/output/extr...  T RAINALD  /content/text_renderer/example_data/output/ext...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPIz3bf67vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(df.labels)):\n",
        "  if type(df.labels[i]) == int:\n",
        "   df.labels[i] = str(df.labels[i])\n",
        "   continue\n",
        "  df.labels[i] = df.labels[i].replace(' ', '')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeS7H_ZtgFYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j90_DdTWkSfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "21a134df-9736-498a-8e2e-545624c77da2"
      },
      "source": [
        "df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FORAL</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FLYIN</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EVERSW</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ORNWHY</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SBOUG</td>\n",
              "      <td>/content/text_renderer/example_data/output/cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>SON30P</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>ESSTREET</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>PERBFIEL</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>UMBTOTH</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>TRAINALD</td>\n",
              "      <td>/content/text_renderer/example_data/output/ext...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         labels                                         image_name\n",
              "0         FORAL  /content/text_renderer/example_data/output/cha...\n",
              "1         FLYIN  /content/text_renderer/example_data/output/cha...\n",
              "2        EVERSW  /content/text_renderer/example_data/output/cha...\n",
              "3        ORNWHY  /content/text_renderer/example_data/output/cha...\n",
              "4         SBOUG  /content/text_renderer/example_data/output/cha...\n",
              "...         ...                                                ...\n",
              "49995    SON30P  /content/text_renderer/example_data/output/ext...\n",
              "49996  ESSTREET  /content/text_renderer/example_data/output/ext...\n",
              "49997  PERBFIEL  /content/text_renderer/example_data/output/ext...\n",
              "49998   UMBTOTH  /content/text_renderer/example_data/output/ext...\n",
              "49999  TRAINALD  /content/text_renderer/example_data/output/ext...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKGLs0WfhiLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[[\"image_name\", \"labels\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YtR8IlU-4vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWSjt3ps-sFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('/content/data.txt', df.values, fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sakxlweL4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "def _int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value= value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1vM6Lurp8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd, os\n",
        "import matplotlib.pyplot as plt, cv2\n",
        "import tensorflow as tf, re, math\n",
        "from skimage import io\n",
        "import imghdr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbP1sCY3zmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles\n",
        "IMGS = getListOfFiles('/content/text_renderer/example_data/output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAQ7DYL5q_EQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b1f4d617-b017-4fa5-fdfc-c4750bb27504"
      },
      "source": [
        "def serialize_example(feature0, feature1, feature2, feature3):\n",
        "  feature = {\n",
        "      'image': _bytes_feature(feature0),\n",
        "      'image_name': _int64_feature(feature1),\n",
        "      'sizes': _int64_list_feature(feature2),\n",
        "      'labels': _bytes_feature(feature3)\n",
        "  }\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()\n",
        "SIZE = 10000\n",
        "CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
        "for j in range(CT):\n",
        "    print(); print('Writing TFRecord %i of %i...'%(j,CT))\n",
        "    CT2 = min(SIZE,len(IMGS)-j*SIZE)\n",
        "    with tf.io.TFRecordWriter('/content/gdrive/My Drive/train%.2i-%i.tfrec'%(j,CT2)) as writer:\n",
        "        for k in range(CT2):\n",
        "            if  imghdr.what(IMGS[k]) == None:\n",
        "              continue\n",
        "            img = cv2.imread(IMGS[k])\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n",
        "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n",
        "            name = IMGS[SIZE*j+k].split('.')[0]\n",
        "            row = df.iloc[k]\n",
        "            example = serialize_example(\n",
        "                img, row.image_name,\n",
        "                row.sizes,\n",
        "                str.encode(row.labels))\n",
        "            writer.write(example)\n",
        "            if k%100==0: print(k,', ',end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing TFRecord 0 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 1 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 2 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 3 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 4 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 5 of 6...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrbBuNWXnd90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE]) # explicit size needed for TPU\n",
        "    print(image)\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "        \"sizes\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "        \"labels\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    sizes = example['sizes']\n",
        "    image = decode_image(example['image'])\n",
        "    image_name = example['image_name']\n",
        "    labels = example['labels']\n",
        "    \n",
        "    return image, labels, image_name, sizes # returns a dataset of (image, label) pairs\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRAn1xTiobLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "71ae5ebb-e16d-4e46-acc8-f63c71e085c6"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE= [220,32]\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob('/content/gdrive/My Drive/tfrecord/*.tfrec')\n",
        "print('There are %i train images'%count_data_items(TRAINING_FILENAMES))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-06e38aeb1731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mAUTO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTRAINING_FILENAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/tfrecord/*.tfrec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are %i train images'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mcount_data_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_FILENAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         for matching_filename in _pywrap_file_io.GetMatchingFiles(\n\u001b[0;32m--> 409\u001b[0;31m             compat.as_bytes(pattern))\n\u001b[0m\u001b[1;32m    410\u001b[0m     ]\n\u001b[1;32m    411\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /content/gdrive/My Drive/tfrecord; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q25b94SPooiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0283ce0a-7f15-4b1f-a60e-8e404967858d"
      },
      "source": [
        "training_dataset = get_training_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(220, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ygtj2lorcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "386c8a35-4b68-4e2c-fe54-1e7eadfd9203"
      },
      "source": [
        "training_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 220, 32), (None,), (None,), (None, None)), types: (tf.float32, tf.string, tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NTT2_tPFIuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74ef49fe-5fd4-46be-c909-aadee4968b0e"
      },
      "source": [
        "%cd '/content'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6gM8C3HxoAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4f44573-af01-42fa-c387-31e34a706447"
      },
      "source": [
        "!git clone https://github.com/sanyam83/License-plate-recognition-using-YOLOv3.git\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "%cd /content/License-plate-recognition-using-YOLOv3\n",
        "from crnn.Image_Generator import TextImageGenerator, labels_to_text\n",
        "from crnn.Model import *\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from crnn.parameter import *\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "# # Model description and training\n",
        "\n",
        "model = get_Model(training=True)\n",
        "\n",
        "train_file_path = '/content/text_renderer/example_data/output'\n",
        "tiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor, df)\n",
        "tiger_train.build_data()\n",
        "\n",
        "\n",
        "ada = Adam(lr=1e-4)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=1)\n",
        "checkpoint = ModelCheckpoint(filepath='LSTM+BN5--{epoch:02d}--{loss:.3f}.hdf5', monitor='loss', verbose=1, mode='min', period=1, save_best_only=True,)\n",
        "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada, metrics=['accuracy'])\n",
        "\n",
        "'''model = load_model('/content/License-plate-recognition-using-YOLOv3/LSTM+BN5--100--0.657.hdf5', custom_objects={'<lambda>': lambda y_true, output: output})'''\n",
        "# captures output of softmax so we can decode the output during visualization\n",
        "history = model.fit_generator(generator=tiger_train.next_batch(),\n",
        "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
        "                    epochs=100,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 25.2488 - accuracy: 0.0000e+00\n",
            "Epoch 00001: loss improved from inf to 25.24882, saving model to LSTM+BN5--01--25.249.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 25.2488 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 23.9622 - accuracy: 0.0000e+00\n",
            "Epoch 00002: loss improved from 25.24882 to 23.96222, saving model to LSTM+BN5--02--23.962.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 23.9622 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 23.5584 - accuracy: 0.0000e+00\n",
            "Epoch 00003: loss improved from 23.96222 to 23.55839, saving model to LSTM+BN5--03--23.558.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 23.5584 - accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 23.4109 - accuracy: 0.0000e+00\n",
            "Epoch 00004: loss improved from 23.55839 to 23.41087, saving model to LSTM+BN5--04--23.411.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 23.4109 - accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 23.1752 - accuracy: 0.0000e+00\n",
            "Epoch 00005: loss improved from 23.41087 to 23.17520, saving model to LSTM+BN5--05--23.175.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 23.1752 - accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 23.0476 - accuracy: 0.0000e+00\n",
            "Epoch 00006: loss improved from 23.17520 to 23.04765, saving model to LSTM+BN5--06--23.048.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 23.0476 - accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 22.8833 - accuracy: 0.0000e+00\n",
            "Epoch 00007: loss improved from 23.04765 to 22.88331, saving model to LSTM+BN5--07--22.883.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 22.8833 - accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 22.6524 - accuracy: 0.0000e+00\n",
            "Epoch 00008: loss improved from 22.88331 to 22.65240, saving model to LSTM+BN5--08--22.652.hdf5\n",
            "781/781 [==============================] - 157s 200ms/step - loss: 22.6524 - accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 22.1928 - accuracy: 0.0000e+00\n",
            "Epoch 00009: loss improved from 22.65240 to 22.19275, saving model to LSTM+BN5--09--22.193.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 22.1928 - accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 21.6017 - accuracy: 0.0000e+00\n",
            "Epoch 00010: loss improved from 22.19275 to 21.60167, saving model to LSTM+BN5--10--21.602.hdf5\n",
            "781/781 [==============================] - 157s 200ms/step - loss: 21.6017 - accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 20.7008 - accuracy: 0.0000e+00\n",
            "Epoch 00011: loss improved from 21.60167 to 20.70083, saving model to LSTM+BN5--11--20.701.hdf5\n",
            "781/781 [==============================] - 157s 200ms/step - loss: 20.7008 - accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 19.5177 - accuracy: 0.0000e+00\n",
            "Epoch 00012: loss improved from 20.70083 to 19.51771, saving model to LSTM+BN5--12--19.518.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 19.5177 - accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 18.2560 - accuracy: 0.0000e+00\n",
            "Epoch 00013: loss improved from 19.51771 to 18.25597, saving model to LSTM+BN5--13--18.256.hdf5\n",
            "781/781 [==============================] - 157s 200ms/step - loss: 18.2560 - accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 16.6981 - accuracy: 1.0003e-04\n",
            "Epoch 00014: loss improved from 18.25597 to 16.69814, saving model to LSTM+BN5--14--16.698.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 16.6981 - accuracy: 1.0003e-04\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 15.1280 - accuracy: 2.8009e-04\n",
            "Epoch 00015: loss improved from 16.69814 to 15.12800, saving model to LSTM+BN5--15--15.128.hdf5\n",
            "781/781 [==============================] - 157s 200ms/step - loss: 15.1280 - accuracy: 2.8009e-04\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 13.6565 - accuracy: 8.0026e-04\n",
            "Epoch 00016: loss improved from 15.12800 to 13.65649, saving model to LSTM+BN5--16--13.656.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 13.6565 - accuracy: 8.0026e-04\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 12.1853 - accuracy: 0.0015\n",
            "Epoch 00017: loss improved from 13.65649 to 12.18531, saving model to LSTM+BN5--17--12.185.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 12.1853 - accuracy: 0.0015\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 10.8428 - accuracy: 0.0031\n",
            "Epoch 00018: loss improved from 12.18531 to 10.84275, saving model to LSTM+BN5--18--10.843.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 10.8428 - accuracy: 0.0031\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 9.5544 - accuracy: 0.0048\n",
            "Epoch 00019: loss improved from 10.84275 to 9.55436, saving model to LSTM+BN5--19--9.554.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 9.5544 - accuracy: 0.0048\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 8.4492 - accuracy: 0.0076\n",
            "Epoch 00020: loss improved from 9.55436 to 8.44920, saving model to LSTM+BN5--20--8.449.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 8.4492 - accuracy: 0.0076\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 7.3957 - accuracy: 0.0106\n",
            "Epoch 00021: loss improved from 8.44920 to 7.39574, saving model to LSTM+BN5--21--7.396.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 7.3957 - accuracy: 0.0106\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 6.4844 - accuracy: 0.0153\n",
            "Epoch 00022: loss improved from 7.39574 to 6.48438, saving model to LSTM+BN5--22--6.484.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 6.4844 - accuracy: 0.0153\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 5.7076 - accuracy: 0.0197\n",
            "Epoch 00023: loss improved from 6.48438 to 5.70758, saving model to LSTM+BN5--23--5.708.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 5.7076 - accuracy: 0.0197\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 5.0114 - accuracy: 0.0273\n",
            "Epoch 00024: loss improved from 5.70758 to 5.01143, saving model to LSTM+BN5--24--5.011.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 5.0114 - accuracy: 0.0273\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 4.4720 - accuracy: 0.0375\n",
            "Epoch 00025: loss improved from 5.01143 to 4.47200, saving model to LSTM+BN5--25--4.472.hdf5\n",
            "781/781 [==============================] - 156s 200ms/step - loss: 4.4720 - accuracy: 0.0375\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 4.0195 - accuracy: 0.0485\n",
            "Epoch 00026: loss improved from 4.47200 to 4.01953, saving model to LSTM+BN5--26--4.020.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 4.0195 - accuracy: 0.0485\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.6242 - accuracy: 0.0634\n",
            "Epoch 00027: loss improved from 4.01953 to 3.62421, saving model to LSTM+BN5--27--3.624.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 3.6242 - accuracy: 0.0634\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 3.4238 - accuracy: 0.0751\n",
            "Epoch 00028: loss improved from 3.62421 to 3.42377, saving model to LSTM+BN5--28--3.424.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 3.4238 - accuracy: 0.0751\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.9920 - accuracy: 0.0977\n",
            "Epoch 00029: loss improved from 3.42377 to 2.99203, saving model to LSTM+BN5--29--2.992.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.9920 - accuracy: 0.0977\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.8627 - accuracy: 0.1129\n",
            "Epoch 00030: loss improved from 2.99203 to 2.86271, saving model to LSTM+BN5--30--2.863.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.8627 - accuracy: 0.1129\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.7355 - accuracy: 0.1278\n",
            "Epoch 00031: loss improved from 2.86271 to 2.73551, saving model to LSTM+BN5--31--2.736.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.7355 - accuracy: 0.1278\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.4744 - accuracy: 0.1522\n",
            "Epoch 00032: loss improved from 2.73551 to 2.47444, saving model to LSTM+BN5--32--2.474.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.4744 - accuracy: 0.1522\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.4613 - accuracy: 0.1629\n",
            "Epoch 00033: loss improved from 2.47444 to 2.46129, saving model to LSTM+BN5--33--2.461.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.4613 - accuracy: 0.1629\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.3290 - accuracy: 0.1792\n",
            "Epoch 00034: loss improved from 2.46129 to 2.32899, saving model to LSTM+BN5--34--2.329.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.3290 - accuracy: 0.1792\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.2087 - accuracy: 0.2048\n",
            "Epoch 00035: loss improved from 2.32899 to 2.20873, saving model to LSTM+BN5--35--2.209.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.2087 - accuracy: 0.2048\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.0948 - accuracy: 0.2218\n",
            "Epoch 00036: loss improved from 2.20873 to 2.09481, saving model to LSTM+BN5--36--2.095.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.0948 - accuracy: 0.2218\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 2.0632 - accuracy: 0.2310\n",
            "Epoch 00037: loss improved from 2.09481 to 2.06321, saving model to LSTM+BN5--37--2.063.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 2.0632 - accuracy: 0.2310\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.9957 - accuracy: 0.2470\n",
            "Epoch 00038: loss improved from 2.06321 to 1.99568, saving model to LSTM+BN5--38--1.996.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.9957 - accuracy: 0.2470\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.9830 - accuracy: 0.2533\n",
            "Epoch 00039: loss improved from 1.99568 to 1.98300, saving model to LSTM+BN5--39--1.983.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.9830 - accuracy: 0.2533\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.8462 - accuracy: 0.2763\n",
            "Epoch 00040: loss improved from 1.98300 to 1.84616, saving model to LSTM+BN5--40--1.846.hdf5\n",
            "781/781 [==============================] - 160s 205ms/step - loss: 1.8462 - accuracy: 0.2763\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.8091 - accuracy: 0.2896\n",
            "Epoch 00041: loss improved from 1.84616 to 1.80909, saving model to LSTM+BN5--41--1.809.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.8091 - accuracy: 0.2896\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.7578 - accuracy: 0.3055\n",
            "Epoch 00042: loss improved from 1.80909 to 1.75781, saving model to LSTM+BN5--42--1.758.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.7578 - accuracy: 0.3055\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.7228 - accuracy: 0.3139\n",
            "Epoch 00043: loss improved from 1.75781 to 1.72285, saving model to LSTM+BN5--43--1.723.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.7228 - accuracy: 0.3139\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.6593 - accuracy: 0.3236\n",
            "Epoch 00044: loss improved from 1.72285 to 1.65928, saving model to LSTM+BN5--44--1.659.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.6593 - accuracy: 0.3236\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.6694 - accuracy: 0.3372\n",
            "Epoch 00045: loss did not improve from 1.65928\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.6694 - accuracy: 0.3372\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.5532 - accuracy: 0.3588\n",
            "Epoch 00046: loss improved from 1.65928 to 1.55318, saving model to LSTM+BN5--46--1.553.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.5532 - accuracy: 0.3588\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.5429 - accuracy: 0.3621\n",
            "Epoch 00047: loss improved from 1.55318 to 1.54292, saving model to LSTM+BN5--47--1.543.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.5429 - accuracy: 0.3621\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4949 - accuracy: 0.3789\n",
            "Epoch 00048: loss improved from 1.54292 to 1.49487, saving model to LSTM+BN5--48--1.495.hdf5\n",
            "781/781 [==============================] - 157s 202ms/step - loss: 1.4949 - accuracy: 0.3789\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.5196 - accuracy: 0.3761\n",
            "Epoch 00049: loss did not improve from 1.49487\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.5196 - accuracy: 0.3761\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4260 - accuracy: 0.4009\n",
            "Epoch 00050: loss improved from 1.49487 to 1.42597, saving model to LSTM+BN5--50--1.426.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.4260 - accuracy: 0.4009\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.3972\n",
            "Epoch 00051: loss did not improve from 1.42597\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.4750 - accuracy: 0.3972\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.4136\n",
            "Epoch 00052: loss improved from 1.42597 to 1.37826, saving model to LSTM+BN5--52--1.378.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.3783 - accuracy: 0.4136\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4698 - accuracy: 0.4027\n",
            "Epoch 00053: loss did not improve from 1.37826\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.4698 - accuracy: 0.4027\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2887 - accuracy: 0.4446\n",
            "Epoch 00054: loss improved from 1.37826 to 1.28868, saving model to LSTM+BN5--54--1.289.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.2887 - accuracy: 0.4446\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.4461\n",
            "Epoch 00055: loss did not improve from 1.28868\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.2963 - accuracy: 0.4461\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.3350 - accuracy: 0.4357\n",
            "Epoch 00056: loss did not improve from 1.28868\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.3350 - accuracy: 0.4357\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2851 - accuracy: 0.4504\n",
            "Epoch 00057: loss improved from 1.28868 to 1.28507, saving model to LSTM+BN5--57--1.285.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.2851 - accuracy: 0.4504\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2625 - accuracy: 0.4592\n",
            "Epoch 00058: loss improved from 1.28507 to 1.26249, saving model to LSTM+BN5--58--1.262.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.2625 - accuracy: 0.4592\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2232 - accuracy: 0.4737\n",
            "Epoch 00059: loss improved from 1.26249 to 1.22322, saving model to LSTM+BN5--59--1.223.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.2232 - accuracy: 0.4737\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.4141 - accuracy: 0.4389\n",
            "Epoch 00060: loss did not improve from 1.22322\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.4141 - accuracy: 0.4389\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1113 - accuracy: 0.5034\n",
            "Epoch 00061: loss improved from 1.22322 to 1.11130, saving model to LSTM+BN5--61--1.111.hdf5\n",
            "781/781 [==============================] - 157s 202ms/step - loss: 1.1113 - accuracy: 0.5034\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0875 - accuracy: 0.5166\n",
            "Epoch 00062: loss improved from 1.11130 to 1.08745, saving model to LSTM+BN5--62--1.087.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.0875 - accuracy: 0.5166\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1933 - accuracy: 0.4903\n",
            "Epoch 00063: loss did not improve from 1.08745\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.1933 - accuracy: 0.4903\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.2194 - accuracy: 0.4851\n",
            "Epoch 00064: loss did not improve from 1.08745\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.2194 - accuracy: 0.4851\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1559 - accuracy: 0.5010\n",
            "Epoch 00065: loss did not improve from 1.08745\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.1559 - accuracy: 0.5010\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1555 - accuracy: 0.5061\n",
            "Epoch 00066: loss did not improve from 1.08745\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 1.1555 - accuracy: 0.5061\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0461 - accuracy: 0.5358\n",
            "Epoch 00067: loss improved from 1.08745 to 1.04614, saving model to LSTM+BN5--67--1.046.hdf5\n",
            "781/781 [==============================] - 157s 202ms/step - loss: 1.0461 - accuracy: 0.5358\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0420 - accuracy: 0.5406\n",
            "Epoch 00068: loss improved from 1.04614 to 1.04196, saving model to LSTM+BN5--68--1.042.hdf5\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.0420 - accuracy: 0.5406\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.1753 - accuracy: 0.5048\n",
            "Epoch 00069: loss did not improve from 1.04196\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.1753 - accuracy: 0.5048\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.9771 - accuracy: 0.5618\n",
            "Epoch 00070: loss improved from 1.04196 to 0.97706, saving model to LSTM+BN5--70--0.977.hdf5\n",
            "781/781 [==============================] - 158s 202ms/step - loss: 0.9771 - accuracy: 0.5618\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.5519\n",
            "Epoch 00071: loss did not improve from 0.97706\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.0049 - accuracy: 0.5519\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - ETA: 0s - loss: 1.0592 - accuracy: 0.5386\n",
            "Epoch 00072: loss did not improve from 0.97706\n",
            "781/781 [==============================] - 157s 201ms/step - loss: 1.0592 - accuracy: 0.5386\n",
            "Epoch 73/100\n",
            "545/781 [===================>..........] - ETA: 47s - loss: 1.0312 - accuracy: 0.5424Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxKHg6EIZYg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3d831b1-15c2-485c-c451-c13b62e01fe7"
      },
      "source": [
        "#Training for 20 more epochs\n",
        "model = load_model('/content/gdrive/My Drive/crnn_checkpoint/LSTM+BN5--94--0.668.hdf5', custom_objects={'<lambda>': lambda y_true, output: output})\n",
        "# captures output of softmax so we can decode the output during visualization\n",
        "model.fit_generator(generator=tiger_train.next_batch(),\n",
        "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
        "                    epochs=20,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.6951\n",
            "Epoch 00001: loss improved from 0.66801 to 0.65881, saving model to /content/gdrive/My Drive/crnn_checkpoint/LSTM+BN5--01--0.659.hdf5\n",
            "781/781 [==============================] - 73s 94ms/step - loss: 0.6588 - accuracy: 0.6951\n",
            "Epoch 2/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8333 - accuracy: 0.6281\n",
            "Epoch 00002: loss did not improve from 0.65881\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.8333 - accuracy: 0.6281\n",
            "Epoch 3/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8013 - accuracy: 0.6405\n",
            "Epoch 00003: loss did not improve from 0.65881\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.8013 - accuracy: 0.6405\n",
            "Epoch 4/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.6769\n",
            "Epoch 00004: loss did not improve from 0.65881\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.7019 - accuracy: 0.6769\n",
            "Epoch 5/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6123\n",
            "Epoch 00005: loss did not improve from 0.65881\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.9149 - accuracy: 0.6123\n",
            "Epoch 6/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6024 - accuracy: 0.7168\n",
            "Epoch 00006: loss improved from 0.65881 to 0.60237, saving model to /content/gdrive/My Drive/crnn_checkpoint/LSTM+BN5--06--0.602.hdf5\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6024 - accuracy: 0.7168\n",
            "Epoch 7/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.6669\n",
            "Epoch 00007: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.7323 - accuracy: 0.6669\n",
            "Epoch 8/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.6616\n",
            "Epoch 00008: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.7436 - accuracy: 0.6616\n",
            "Epoch 9/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7705 - accuracy: 0.6586\n",
            "Epoch 00009: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.7705 - accuracy: 0.6586\n",
            "Epoch 10/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.7104\n",
            "Epoch 00010: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6232 - accuracy: 0.7104\n",
            "Epoch 11/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.6823\n",
            "Epoch 00011: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6944 - accuracy: 0.6823\n",
            "Epoch 12/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.6748\n",
            "Epoch 00012: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.7086 - accuracy: 0.6748\n",
            "Epoch 13/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.7231 - accuracy: 0.6744\n",
            "Epoch 00013: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.7231 - accuracy: 0.6744\n",
            "Epoch 14/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6420 - accuracy: 0.7035\n",
            "Epoch 00014: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6420 - accuracy: 0.7035\n",
            "Epoch 15/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.6983\n",
            "Epoch 00015: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6560 - accuracy: 0.6983\n",
            "Epoch 16/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.6390\n",
            "Epoch 00016: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 72s 93ms/step - loss: 0.8504 - accuracy: 0.6390\n",
            "Epoch 17/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.7091\n",
            "Epoch 00017: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 93ms/step - loss: 0.6426 - accuracy: 0.7091\n",
            "Epoch 18/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.7184\n",
            "Epoch 00018: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 94ms/step - loss: 0.6166 - accuracy: 0.7184\n",
            "Epoch 19/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.7158\n",
            "Epoch 00019: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 94ms/step - loss: 0.6257 - accuracy: 0.7158\n",
            "Epoch 20/20\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.6878 - accuracy: 0.6907\n",
            "Epoch 00020: loss did not improve from 0.60237\n",
            "781/781 [==============================] - 73s 94ms/step - loss: 0.6878 - accuracy: 0.6907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f968dd2cc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nb3XDl79nEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import itertools, os, time\n",
        "import numpy as np\n",
        "from crnn.Model import get_Model\n",
        "from crnn.parameter import letters\n",
        "import argparse\n",
        "from keras import backend as K\n",
        "K.set_learning_phase(0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot2-osHEN-SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_Model(training=False)\n",
        "model.load_weights('/content/gdrive/My Drive/crnn_checkpoint/LSTM+BN5--06--0.602.hdf5')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHnv91QmOdj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_label(out):\n",
        "    # out : (1, 32, 42)\n",
        "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index -> len = 32\n",
        "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
        "    outstr = ''\n",
        "    for i in out_best:\n",
        "        if i < len(letters):\n",
        "            outstr += letters[i]\n",
        "    return outstr"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdhEGMxr6cA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "import pytesseract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPlTwpxCzb88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread('/content/text_renderer/example_data/output/extra_text_line_data/images/000040054.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "img_pred = img.astype(np.float32)\n",
        "img_pred = cv2.resize(img_pred, (32, 128))\n",
        "img_pred = (img_pred / 255.0) * 2.0 - 1.0\n",
        "img_pred = np.expand_dims(img_pred, axis=-1)\n",
        "img_pred = np.expand_dims(img_pred, axis=0)\n",
        "net_out_value = model.predict(img_pred)\n",
        "pred_texts = decode_label(net_out_value)\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcUZRDGiOtcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae05fd7c-8501-495a-9e6c-1fb2129323f6"
      },
      "source": [
        "pred_texts"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TEEFOHENHE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK50S5JU76zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "1ab6c94a-8f19-42fd-9899-f54f58e98e5f"
      },
      "source": [
        "from PIL import Image\n",
        "im = Image.open(\"/content/5.png\")\n",
        "text = pytesseract.image_to_string(im)\n",
        "print(text) "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-777c45a10acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/5.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2860\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomposite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m     \"\"\"\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/content/5.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8wcMSwJpysY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcz1CyPYV8wA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "65c03c61-79cb-499b-f096-9b705a9b21d3"
      },
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC2CC76SpO3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}