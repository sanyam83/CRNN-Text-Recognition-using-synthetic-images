{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Internship Assignment",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etk0INVcDiVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d25ae7c2-ce3b-4ccf-a23e-60ed85009953"
      },
      "source": [
        "g_drive_path = '/content/gdrive'\n",
        "from google.colab import drive\n",
        "drive.mount(g_drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfYUb5bx3nmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "813fb412-a0d6-4d03-e6d3-15a878f21273"
      },
      "source": [
        "!git clone https://github.com/sanyam83/text_renderer.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'text_renderer'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 656 (delta 0), reused 0 (delta 0), pack-reused 653\u001b[K\n",
            "Receiving objects: 100% (656/656), 11.61 MiB | 17.43 MiB/s, done.\n",
            "Resolving deltas: 100% (312/312), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MAtpOL4Z3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a96a516a-b756-4033-b45c-7e41d50910d5"
      },
      "source": [
        "%cd /content/text_renderer\n",
        "!python setup.py develop"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/text_renderer\n",
            "running develop\n",
            "running egg_info\n",
            "creating text_renderer.egg-info\n",
            "writing text_renderer.egg-info/PKG-INFO\n",
            "writing dependency_links to text_renderer.egg-info/dependency_links.txt\n",
            "writing top-level names to text_renderer.egg-info/top_level.txt\n",
            "writing manifest file 'text_renderer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'text_renderer.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/text-renderer.egg-link (link to .)\n",
            "Adding text-renderer 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/text_renderer\n",
            "Processing dependencies for text-renderer==0.0.1\n",
            "Finished processing dependencies for text-renderer==0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-Nm2Ah4j4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c389532e-cb95-4173-9f75-51cf8af47cee"
      },
      "source": [
        "!pip install -r docker/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python==3.4.5.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e1/d3eed618272f4b746339af1a84b2511e79c1708d88a9195cf25d743fa614/opencv_python-3.4.5.20-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 109kB/s \n",
            "\u001b[?25hCollecting fontTools==4.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/80/6703106d6e3a56d0b124a2a1b3159d70ef383282b428a385bbee39762030/fonttools-4.12.1-py3-none-any.whl (803kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 53.0MB/s \n",
            "\u001b[?25hCollecting lmdb==0.98\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/5c/d56dbc2532ecf14fa004c543927500c0f645eaca8bd7ec39420c7546396a/lmdb-0.98.tar.gz (869kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 23.6MB/s \n",
            "\u001b[?25hCollecting pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 5)) (1.18.5)\n",
            "Collecting tenacity\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/05/ff089032442058bd3386f9cd991cd88ccac81dca1494d78751621ee35e62/tenacity-6.2.0-py2.py3-none-any.whl\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 8)) (4.41.1)\n",
            "Collecting loguru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/4f/baee593c195cd4b56cf008c9473347f3b0795b47d3b946e03706a8b43fca/loguru-0.5.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 10)) (1.14.2)\n",
            "Collecting sphinx==3.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/bb/bbe3f555751da411ed892526d0d78ed1b9ff2a25ed2b0dab9f2670c8da07/Sphinx-3.1.2-py3-none-any.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.2MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/86/1addf25a238bbd8466bb099f23d9a9f13494b22b37b44f6c41a778b8730f/sphinx_rtd_theme-0.5.0-py2.py3-none-any.whl (10.8MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8MB 138kB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 13)) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 14)) (3.6.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tenacity->-r docker/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->-r docker/requirements.txt (line 7)) (1.1.0)\n",
            "Collecting aiocontextvars>=0.2.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c1/7a723e8d988de0a2e623927396e54b6831b68cb80dce468c945b849a9385/aiocontextvars-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->-r docker/requirements.txt (line 10)) (2.20)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.1.3)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (49.6.0)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 58.2MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils>=0.12 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (0.15.2)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.1.4)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.0.0)\n",
            "Collecting sphinxcontrib-htmlhelp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.8.0)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx==3.1.2->-r docker/requirements.txt (line 11)) (20.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (20.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (8.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (1.9.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r docker/requirements.txt (line 14)) (1.4.0)\n",
            "Collecting contextvars==2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.0->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2020.6.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel>=1.3->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx==3.1.2->-r docker/requirements.txt (line 11)) (2.4.7)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: lmdb, fire, contextvars\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-0.98-cp36-cp36m-linux_x86_64.whl size=218596 sha256=0251f56d9b8ed8699d5eacc752c48a65544e324e1df4cde8f9b6b43041558e09\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/97/8c/7721e4b6b0ac723c6cc45ecca60599a80f75e2367330647390\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=435f057f60d0cef76b4d3d3a84c65cfbb817d93a07d52bc0a58bd82a41e9b988\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=0156ba6d1008c5ff05a9db1204a44a0f7e344220b7bbb67f45b2b8521b870e52\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built lmdb fire contextvars\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python, fontTools, lmdb, pillow, tenacity, fire, immutables, contextvars, aiocontextvars, loguru, sphinxcontrib-applehelp, sphinxcontrib-devhelp, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-jsmath, sphinx, sphinx-rtd-theme\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Found existing installation: Sphinx 1.8.5\n",
            "    Uninstalling Sphinx-1.8.5:\n",
            "      Successfully uninstalled Sphinx-1.8.5\n",
            "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 fire-0.3.1 fontTools-4.12.1 immutables-0.14 lmdb-0.98 loguru-0.5.1 opencv-python-3.4.5.20 pillow-6.2.2 sphinx-3.1.2 sphinx-rtd-theme-0.5.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 tenacity-6.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqWGJwo6God",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ef85e3fd-04bd-4df4-ce45-bf5d3182ae16"
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] --config CONFIG [--dataset {lmdb,img}]\n",
            "               [--num_processes NUM_PROCESSES] [--log_period LOG_PERIOD]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --config CONFIG       python file path\n",
            "  --dataset {lmdb,img}\n",
            "  --num_processes NUM_PROCESSES\n",
            "  --log_period LOG_PERIOD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49C3qavAaHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cba22490-2d55-450c-f4b7-e3ad58f42022"
      },
      "source": [
        "!python main.py \\\n",
        "    --config example_data/example.py \\\n",
        "    --dataset img \\\n",
        "    --num_processes 1 \\\n",
        "    --log_period 10"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m2020-08-27 17:04:59.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/eng.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/eng.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.00%(0) chars in input text。Unique chars(0): set()\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.word_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mLoad 158 words\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.00%(0) chars in input text。Unique chars(0): set()\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:04:59.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/chn_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.char_corpus\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mload: /content/text_renderer/example_data/text/eng_text.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mFind space in line 0 when load /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.utils.utils\u001b[0m:\u001b[36mload_chars_file\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mload 37 chars from: /content/text_renderer/example_data/char/chn.txt\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mfiltering text by chars...\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtext_renderer.corpus.corpus\u001b[0m:\u001b[36mfilter_by_chars\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mFilter 0.12%(2) chars in input text。Unique chars(1): {'\\n'}\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/char_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-27 17:05:00.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 476\u001b[0m\n",
            "\u001b[32m2020-08-27 17:06:27.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-27 17:06:27.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m100.00%(10000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-27 17:06:27.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 10000. Total: 10000\u001b[0m\n",
            "\u001b[32m2020-08-27 17:06:28.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/rand_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-27 17:06:28.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 30516\u001b[0m\n",
            "\u001b[32m2020-08-27 17:07:21.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-27 17:07:21.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m200.00%(20000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-27 17:07:21.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 20000. Total: 20000\u001b[0m\n",
            "\u001b[32m2020-08-27 17:07:22.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/word_corpus: 0\u001b[0m\n",
            "\u001b[32m2020-08-27 17:07:22.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 60543\u001b[0m\n",
            "\u001b[32m2020-08-27 17:08:39.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-27 17:08:39.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m300.00%(30000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-27 17:08:39.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 30000. Total: 30000\u001b[0m\n",
            "\u001b[32m2020-08-27 17:08:40.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/same_line_data: 0\u001b[0m\n",
            "\u001b[32m2020-08-27 17:08:40.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 90576\u001b[0m\n",
            "\u001b[32m2020-08-27 17:11:48.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-27 17:11:48.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m400.00%(40000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-27 17:11:48.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 40000. Total: 40000\u001b[0m\n",
            "\u001b[32m2020-08-27 17:11:48.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mExist image count in /content/text_renderer/example_data/output/extra_text_line_data: 0\u001b[0m\n",
            "\u001b[32m2020-08-27 17:11:48.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_setup\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mFinish setup image generate process: 120646\u001b[0m\n",
            "\u001b[32m2020-08-27 17:13:16.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mDBWriterProcess receive stop token\u001b[0m\n",
            "\u001b[32m2020-08-27 17:13:16.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m500.00%(50000/10000)\u001b[0m\n",
            "\u001b[32m2020-08-27 17:13:16.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mFinish generate: 50000. Total: 50000\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izVrU4o8bOy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json \n",
        "import csv \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json ('/content/text_renderer/example_data/output/word_corpus/labels.json')  \n",
        "df.to_csv ('/content/text_renderer/data_sample.csv', index = None, header=True)  \n",
        "df_1 = pd.read_json('/content/text_renderer/example_data/output/char_corpus/labels.json')\n",
        "df_1.to_csv ('/content/text_renderer/data_sample_1.csv', index = None, header=True)  \n",
        "df_2 = pd.read_json ('/content/text_renderer/example_data/output/extra_text_line_data/labels.json')  \n",
        "df_2.to_csv ('/content/text_renderer/data_sample_2.csv', index = None, header=True)  \n",
        "df_3 = pd.read_json('/content/text_renderer/example_data/output/rand_corpus/labels.json')\n",
        "df_3.to_csv ('/content/text_renderer/data_sample_3.csv', index = None, header=True)  \n",
        "df_4 = pd.read_json('/content/text_renderer/example_data/output/same_line_data/labels.json')\n",
        "df_4.to_csv ('/content/text_renderer/data_sample_4.csv', index = None, header=True)  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmZy0GDzTFvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "abc6a18f-ea7d-4f75-fefa-a7f16dda76ae"
      },
      "source": [
        "df_3"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num-samples</th>\n",
              "      <th>labels</th>\n",
              "      <th>sizes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>20000</td>\n",
              "      <td>29486954</td>\n",
              "      <td>[174, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>20000</td>\n",
              "      <td>9277646</td>\n",
              "      <td>[151, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>20000</td>\n",
              "      <td>449769</td>\n",
              "      <td>[116, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>20000</td>\n",
              "      <td>70851538</td>\n",
              "      <td>[180, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>20000</td>\n",
              "      <td>17708</td>\n",
              "      <td>[103, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>20000</td>\n",
              "      <td>4169873</td>\n",
              "      <td>[154, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>20000</td>\n",
              "      <td>50209</td>\n",
              "      <td>[106, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>20000</td>\n",
              "      <td>87838641</td>\n",
              "      <td>[172, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>20000</td>\n",
              "      <td>81984</td>\n",
              "      <td>[109, 32]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>20000</td>\n",
              "      <td>10821</td>\n",
              "      <td>[102, 32]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       num-samples    labels      sizes\n",
              "10000        20000  29486954  [174, 32]\n",
              "10001        20000   9277646  [151, 32]\n",
              "10002        20000    449769  [116, 32]\n",
              "10003        20000  70851538  [180, 32]\n",
              "10004        20000     17708  [103, 32]\n",
              "...            ...       ...        ...\n",
              "19995        20000   4169873  [154, 32]\n",
              "19996        20000     50209  [106, 32]\n",
              "19997        20000  87838641  [172, 32]\n",
              "19998        20000     81984  [109, 32]\n",
              "19999        20000     10821  [102, 32]\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udje1O1XObch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([df_1, df_3, df, df_4, df_2], axis = 0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqPSTpVLTuuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['num-samples'], axis = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUGf8xIT7ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['image_name'] = df.index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScYRd94bPkIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "19b3d9c1-2b78-40df-aba8-2215385c212c"
      },
      "source": [
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>sizes</th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ONCE</td>\n",
              "      <td>[141, 32]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AND KEEP</td>\n",
              "      <td>[237, 32]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FOR ALL</td>\n",
              "      <td>[244, 32]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DO WE</td>\n",
              "      <td>[190, 32]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CTOR TO</td>\n",
              "      <td>[237, 32]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>R TRIED T</td>\n",
              "      <td>[157, 32]</td>\n",
              "      <td>49995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>BEFORE EA</td>\n",
              "      <td>[154, 32]</td>\n",
              "      <td>49996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>AS DUE TO</td>\n",
              "      <td>[138, 32]</td>\n",
              "      <td>49997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>POINT PEN</td>\n",
              "      <td>[159, 32]</td>\n",
              "      <td>49998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>POINT PEN</td>\n",
              "      <td>[176, 32]</td>\n",
              "      <td>49999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          labels      sizes  image_name\n",
              "0           ONCE  [141, 32]           0\n",
              "1       AND KEEP  [237, 32]           1\n",
              "2        FOR ALL  [244, 32]           2\n",
              "3         DO WE   [190, 32]           3\n",
              "4        CTOR TO  [237, 32]           4\n",
              "...          ...        ...         ...\n",
              "49995  R TRIED T  [157, 32]       49995\n",
              "49996  BEFORE EA  [154, 32]       49996\n",
              "49997  AS DUE TO  [138, 32]       49997\n",
              "49998  POINT PEN  [159, 32]       49998\n",
              "49999  POINT PEN  [176, 32]       49999\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPIz3bf67vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "285d7cfc-d8ae-4102-c579-b7294f2fb47f"
      },
      "source": [
        "df['labels'][0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ONCE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sakxlweL4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "def _int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value= value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu1vM6Lurp8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd, os\n",
        "import matplotlib.pyplot as plt, cv2\n",
        "import tensorflow as tf, re, math\n",
        "from skimage import io\n",
        "import imghdr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RbP1sCY3zmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles\n",
        "IMGS = getListOfFiles('/content/text_renderer/example_data/output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAQ7DYL5q_EQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b1f4d617-b017-4fa5-fdfc-c4750bb27504"
      },
      "source": [
        "def serialize_example(feature0, feature1, feature2, feature3):\n",
        "  feature = {\n",
        "      'image': _bytes_feature(feature0),\n",
        "      'image_name': _int64_feature(feature1),\n",
        "      'sizes': _int64_list_feature(feature2),\n",
        "      'labels': _bytes_feature(feature3)\n",
        "  }\n",
        "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "  return example_proto.SerializeToString()\n",
        "SIZE = 10000\n",
        "CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
        "for j in range(CT):\n",
        "    print(); print('Writing TFRecord %i of %i...'%(j,CT))\n",
        "    CT2 = min(SIZE,len(IMGS)-j*SIZE)\n",
        "    with tf.io.TFRecordWriter('/content/gdrive/My Drive/train%.2i-%i.tfrec'%(j,CT2)) as writer:\n",
        "        for k in range(CT2):\n",
        "            if  imghdr.what(IMGS[k]) == None:\n",
        "              continue\n",
        "            img = cv2.imread(IMGS[k])\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n",
        "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n",
        "            name = IMGS[SIZE*j+k].split('.')[0]\n",
        "            row = df.iloc[k]\n",
        "            example = serialize_example(\n",
        "                img, row.image_name,\n",
        "                row.sizes,\n",
        "                str.encode(row.labels))\n",
        "            writer.write(example)\n",
        "            if k%100==0: print(k,', ',end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing TFRecord 0 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 1 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 2 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 3 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 4 of 6...\n",
            "100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , \n",
            "Writing TFRecord 5 of 6...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrbBuNWXnd90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE]) # explicit size needed for TPU\n",
        "    print(image)\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "        \"sizes\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "        \"labels\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    sizes = example['sizes']\n",
        "    image = decode_image(example['image'])\n",
        "    image_name = example['image_name']\n",
        "    labels = example['labels']\n",
        "    \n",
        "    return image, labels, image_name, sizes # returns a dataset of (image, label) pairs\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(read_labeled_tfrecord)\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
        "    return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRAn1xTiobLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE= [220,32]\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob('/content/gdrive/My Drive/tfrecord/*.tfrec')\n",
        "print('There are %i train images'%count_data_items(TRAINING_FILENAMES))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q25b94SPooiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0283ce0a-7f15-4b1f-a60e-8e404967858d"
      },
      "source": [
        "training_dataset = get_training_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(220, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ygtj2lorcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "386c8a35-4b68-4e2c-fe54-1e7eadfd9203"
      },
      "source": [
        "training_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 220, 32), (None,), (None,), (None, None)), types: (tf.float32, tf.string, tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NTT2_tPFIuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7652222-fa1d-4041-ec87-e306aec74615"
      },
      "source": [
        "%cd '/content'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6gM8C3HxoAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/sanyam83/License-plate-recognition-using-YOLOv3.git\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "%cd /content/License-plate-recognition-using-YOLOv3\n",
        "from crnn.Image_Generator import TextImageGenerator\n",
        "from crnn.Model import get_Model\n",
        "from crnn.parameter import *\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "# # Model description and training\n",
        "\n",
        "model = get_Model(training=True)\n",
        "\n",
        "train_file_path = '/content/text_renderer/example_data/output'\n",
        "tiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor, df)\n",
        "tiger_train.build_data()\n",
        "\n",
        "\n",
        "ada = Adam(lr=1e-4)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=1)\n",
        "checkpoint = ModelCheckpoint(filepath='LSTM+BN5--{epoch:02d}--{loss:.3f}.hdf5', monitor='loss', verbose=1, mode='min', period=1)\n",
        "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
        "\n",
        "# captures output of softmax so we can decode the output during visualization\n",
        "model.fit_generator(generator=tiger_train.next_batch(),\n",
        "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
        "                    epochs=30,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nb3XDl79nEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}